{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data Acquisition and Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Path to dataset\n",
    "dataset_path = r\"../data/raw_img/parking\"\n",
    "\n",
    "# Get file list with details\n",
    "file_details = []\n",
    "for file in os.listdir(dataset_path):\n",
    "    file_path = os.path.join(dataset_path, file)\n",
    "    file_size = os.path.getsize(file_path) / (1024 * 1024)  # Convert size to MB\n",
    "    file_ext = os.path.splitext(file)[1]\n",
    "    \n",
    "    file_details.append([file, file_ext, f\"{file_size:.2f} MB\"])\n",
    "\n",
    "# Create table\n",
    "print(tabulate(file_details, headers=[\"Filename\", \"Extension\", \"Size\"], tablefmt=\"pretty\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from icecream import ic\n",
    "\n",
    "# Since the dataset consists of .mp4 videos, we need to extract frames to analyze the parking lot structure.\n",
    "\n",
    "# Path to a sample video\n",
    "video_path = os.path.join(dataset_path, \"parking_crop.mp4\")\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "def extract_sample_frames(video_path, frame_interval=100, output_dir_name=None):\n",
    "    \"\"\"\n",
    "    Extracts and saves sample frames from a video file.\n",
    "    \n",
    "    Parameters:\n",
    "        video_path (str): Path to the input video file.\n",
    "        frame_interval (int): Interval at which frames are saved (default is every 100 frames).\n",
    "        output_dir_name (str, optional): Name of the directory to save extracted frames.\n",
    "            If not provided, a new directory named after the video file (without extension) \n",
    "            will be created in the same directory as the video.\n",
    "    \"\"\"\n",
    "    output_dir = os.path.splitext(video_path)[0]  # Use video name as folder\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    for frame_idx in range(0, total_frames, frame_interval):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)  # Jump to frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_filename = os.path.join(output_dir, f\"sample_frame_{frame_idx}.jpg\")\n",
    "        cv2.imwrite(frame_filename, frame)\n",
    "        print(f\"Saved: {frame_filename}\")\n",
    "    cap.release()\n",
    "    print(\"Frame extraction complete.\")\n",
    "\n",
    "extract_sample_frames(video_path)\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_random_frames(frame_directory, num_frames=10):\n",
    "    \"\"\"\n",
    "    Randomly selects 'num_frames' image files from the given directory \n",
    "    and displays them in a single combined figure.\n",
    "    \n",
    "    Parameters:\n",
    "        frame_directory (str): Directory containing frame images.\n",
    "        num_frames (int): Number of random frames to display (default is 10).\n",
    "    \"\"\"\n",
    "    # Get list of image files (considering common image extensions)\n",
    "    image_files = [f for f in os.listdir(frame_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No image files found in the directory.\")\n",
    "        return\n",
    "    \n",
    "    # If there are fewer images than required, use all of them\n",
    "    if len(image_files) < num_frames:\n",
    "        print(f\"Warning: Only {len(image_files)} images found. Displaying all.\")\n",
    "        selected_files = image_files\n",
    "    else:\n",
    "        selected_files = random.sample(image_files, num_frames)\n",
    "    \n",
    "    # Set up the grid for display: 2 rows and 5 columns (or adjust accordingly)\n",
    "    cols = 5\n",
    "    rows = (num_frames + cols - 1) // cols  # ensures sufficient rows\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    for i, image_file in enumerate(selected_files):\n",
    "        image_path = os.path.join(frame_directory, image_file)\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image: {image_file}\")\n",
    "            continue\n",
    "        # Convert image from BGR (OpenCV) to RGB (matplotlib)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.title(image_file, fontsize=8)\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "frames_directory = r'..\\data\\raw_img\\parking\\parking_crop'\n",
    "display_random_frames(frames_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Parking Lot Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Re-import necessary libraries since execution state was reset\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def check_mask_alignment_multiple(mask_path, frames_dir, num_frames=5):\n",
    "    \"\"\"\n",
    "    Loads a mask image and compares it to 'num_frames' randomly selected frames from 'frames_dir'.\n",
    "    Displays each original frame alongside its mask overlay.\n",
    "    \n",
    "    Parameters:\n",
    "        mask_path (str): Path to the mask image (e.g., \"mask_1920_1080.png\").\n",
    "        frames_dir (str): Path to the directory containing extracted frames (e.g., \"parking_1920_1080\").\n",
    "        num_frames (int): Number of frames to compare against the mask (default is 5).\n",
    "    \"\"\"\n",
    "    # Load the mask in grayscale\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None:\n",
    "        print(f\"Error loading mask: {mask_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get a list of image files in the frames directory\n",
    "    frame_files = [\n",
    "        f for f in os.listdir(frames_dir)\n",
    "        if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "    ]\n",
    "    \n",
    "    if not frame_files:\n",
    "        print(f\"No frame images found in '{frames_dir}'.\")\n",
    "        return\n",
    "    \n",
    "    # Select 'num_frames' randomly from the available frames\n",
    "    selected_files = random.sample(frame_files, min(num_frames, len(frame_files)))\n",
    "\n",
    "    # Set up the figure size based on the number of frames\n",
    "    fig, axes = plt.subplots(len(selected_files), 2, figsize=(12, 6 * len(selected_files)))\n",
    "\n",
    "    for i, frame_file in enumerate(selected_files):\n",
    "        frame_path = os.path.join(frames_dir, frame_file)\n",
    "        \n",
    "        # Load the selected frame\n",
    "        frame = cv2.imread(frame_path)\n",
    "        if frame is None:\n",
    "            print(f\"Error loading frame: {frame_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Resize mask if necessary\n",
    "        if (mask.shape[0] != frame.shape[0]) or (mask.shape[1] != frame.shape[1]):\n",
    "            mask_resized = cv2.resize(mask, (frame.shape[1], frame.shape[0]))\n",
    "        else:\n",
    "            mask_resized = mask\n",
    "\n",
    "        # Create an overlay by blending the frame and mask\n",
    "        mask_3ch = cv2.cvtColor(mask_resized, cv2.COLOR_GRAY2BGR)\n",
    "        overlay = cv2.addWeighted(frame, 0.7, mask_3ch, 0.3, 0)\n",
    "\n",
    "        # Convert BGR to RGB for display\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        overlay_rgb = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Display each frame with its mask overlay\n",
    "        if len(selected_files) > 1:\n",
    "            axes[i, 0].imshow(frame_rgb)\n",
    "            axes[i, 0].set_title(f\"Original Frame: {frame_file}\")\n",
    "            axes[i, 0].axis(\"off\")\n",
    "\n",
    "            axes[i, 1].imshow(overlay_rgb)\n",
    "            axes[i, 1].set_title(f\"Overlay with Mask: {frame_file}\")\n",
    "            axes[i, 1].axis(\"off\")\n",
    "        else:\n",
    "            axes[0].imshow(frame_rgb)\n",
    "            axes[0].set_title(f\"Original Frame: {frame_file}\")\n",
    "            axes[0].axis(\"off\")\n",
    "\n",
    "            axes[1].imshow(overlay_rgb)\n",
    "            axes[1].set_title(f\"Overlay with Mask: {frame_file}\")\n",
    "            axes[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "check_mask_alignment_multiple(\n",
    "    r\"../data/raw_img/parking/mask_crop.png\", \n",
    "    r\"../data/raw_img/parking/parking_crop\", \n",
    "    num_frames=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from icecream import ic\n",
    "from ultralytics import YOLO\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Check if GPU is available, otherwise use CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the YOLOv5 model (yolov5s is a small, fast variant)\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "model_path = \"yolo11n\"  # automatic download if not found\n",
    "\n",
    "\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True)\n",
    "model = YOLO(model_path).to(device)\n",
    "\n",
    "# # Set confidence threshold \n",
    "# model.conf = 0.2\n",
    "\n",
    "def detect_vehicles_only(image_path, model, confidence_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Detect only certain vehicles (car, truck, bus) above 'confidence_threshold'.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    results = model.predict(img)\n",
    "    \n",
    "    # The first item in 'results' is your predictions object\n",
    "    preds = results[0]\n",
    "    \n",
    "    for box in preds.boxes:\n",
    "        cls_id = int(box.cls[0])        # Class ID (integer)\n",
    "        conf = float(box.conf[0])      # Confidence score\n",
    "        class_name = model.names[cls_id]  # e.g. \"car\", \"person\", etc.\n",
    "        \n",
    "        # Filter by confidence and class name\n",
    "        if conf > confidence_threshold and class_name in [\"car\", \"bus\", \"truck\"]:\n",
    "            # Box coordinates in [x1, y1, x2, y2] format\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            \n",
    "            # Draw a rectangle around the detected object\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            \n",
    "            # Optionally put label + confidence\n",
    "            label = f\"{class_name} {conf:.2f}\"\n",
    "            cv2.putText(img, label, (x1, y1 - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the final image in matplotlib\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "image_path = os.path.join(dataset_path, \"parking_crop\", \"sample_frame_0.jpg\")\n",
    "detect_vehicles_only(image_path, model, confidence_threshold=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['tkinter'] not found, attempting AutoUpdate...\n",
      "Retry 1/2 failed: Command 'pip install --no-cache-dir \"tkinter\" ' returned non-zero exit status 1.\n",
      "Retry 2/2 failed: Command 'pip install --no-cache-dir \"tkinter\" ' returned non-zero exit status 1.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  Command 'pip install --no-cache-dir \"tkinter\" ' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import solutions\n",
    "\n",
    "# Create a ParkingPtsSelection instance\n",
    "selector = solutions.ParkingPtsSelection()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics Solutions:  {'region': None, 'show_in': True, 'show_out': True, 'colormap': None, 'up_angle': 145.0, 'down_angle': 90, 'kpts': [6, 8, 10], 'analytics_type': 'line', 'json_file': 'bounding_boxes.json', 'records': 5, 'model_path': 'yolov8n'}\n",
      "\n",
      "0: 640x544 1 spoon, 1 microwave, 5 ovens, 92.7ms\n",
      "Speed: 4.7ms preprocess, 92.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 1 spoon, 1 microwave, 5 ovens, 69.2ms\n",
      "Speed: 2.6ms preprocess, 69.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 1 microwave, 4 ovens, 72.0ms\n",
      "Speed: 2.9ms preprocess, 72.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 1 microwave, 5 ovens, 72.4ms\n",
      "Speed: 2.8ms preprocess, 72.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 1 microwave, 3 ovens, 68.2ms\n",
      "Speed: 2.9ms preprocess, 68.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 2 ovens, 74.5ms\n",
      "Speed: 3.5ms preprocess, 74.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 2 ovens, 71.1ms\n",
      "Speed: 2.7ms preprocess, 71.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 2 ovens, 70.7ms\n",
      "Speed: 3.3ms preprocess, 70.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 2 ovens, 62.4ms\n",
      "Speed: 2.4ms preprocess, 62.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 3 ovens, 58.4ms\n",
      "Speed: 3.7ms preprocess, 58.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 3 ovens, 66.4ms\n",
      "Speed: 2.8ms preprocess, 66.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 3 ovens, 62.0ms\n",
      "Speed: 4.1ms preprocess, 62.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 2 ovens, 63.8ms\n",
      "Speed: 2.6ms preprocess, 63.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 2 ovens, 113.4ms\n",
      "Speed: 4.9ms preprocess, 113.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 1 oven, 72.4ms\n",
      "Speed: 3.9ms preprocess, 72.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 2 ovens, 71.9ms\n",
      "Speed: 3.0ms preprocess, 71.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 4 ovens, 64.2ms\n",
      "Speed: 3.0ms preprocess, 64.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 3 ovens, 68.2ms\n",
      "Speed: 2.8ms preprocess, 68.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 2 ovens, 64.7ms\n",
      "Speed: 2.7ms preprocess, 64.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 2 ovens, 67.1ms\n",
      "Speed: 3.6ms preprocess, 67.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 2 ovens, 71.4ms\n",
      "Speed: 2.7ms preprocess, 71.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 2 ovens, 66.8ms\n",
      "Speed: 2.5ms preprocess, 66.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 1 bowl, 2 ovens, 68.0ms\n",
      "Speed: 4.9ms preprocess, 68.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 1 bowl, 2 ovens, 65.2ms\n",
      "Speed: 2.8ms preprocess, 65.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 1 bowl, 2 ovens, 68.5ms\n",
      "Speed: 2.7ms preprocess, 68.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 1 bowl, 2 ovens, 67.7ms\n",
      "Speed: 5.0ms preprocess, 67.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 1 bowl, 2 ovens, 76.0ms\n",
      "Speed: 2.8ms preprocess, 76.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 2 ovens, 71.5ms\n",
      "Speed: 3.0ms preprocess, 71.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 2 ovens, 70.0ms\n",
      "Speed: 3.1ms preprocess, 70.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 2 ovens, 63.3ms\n",
      "Speed: 3.3ms preprocess, 63.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 1 bowl, 2 ovens, 71.0ms\n",
      "Speed: 2.9ms preprocess, 71.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 3 ovens, 69.6ms\n",
      "Speed: 3.8ms preprocess, 69.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 3 ovens, 66.3ms\n",
      "Speed: 2.2ms preprocess, 66.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 4 ovens, 65.1ms\n",
      "Speed: 2.4ms preprocess, 65.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 4 ovens, 68.5ms\n",
      "Speed: 2.7ms preprocess, 68.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 3 ovens, 60.9ms\n",
      "Speed: 3.1ms preprocess, 60.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 1 bowl, 4 ovens, 67.8ms\n",
      "Speed: 2.7ms preprocess, 67.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 4 ovens, 87.4ms\n",
      "Speed: 14.6ms preprocess, 87.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 1 bowl, 4 ovens, 125.4ms\n",
      "Speed: 2.5ms preprocess, 125.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 4 ovens, 66.5ms\n",
      "Speed: 3.3ms preprocess, 66.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 3 ovens, 64.1ms\n",
      "Speed: 2.9ms preprocess, 64.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 3 ovens, 61.7ms\n",
      "Speed: 3.6ms preprocess, 61.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 3 ovens, 64.8ms\n",
      "Speed: 2.6ms preprocess, 64.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 3 ovens, 68.3ms\n",
      "Speed: 2.8ms preprocess, 68.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 4 ovens, 74.7ms\n",
      "Speed: 2.9ms preprocess, 74.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 3 ovens, 63.0ms\n",
      "Speed: 3.7ms preprocess, 63.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 3 ovens, 66.0ms\n",
      "Speed: 2.8ms preprocess, 66.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 3 ovens, 62.1ms\n",
      "Speed: 3.1ms preprocess, 62.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 3 ovens, 77.7ms\n",
      "Speed: 2.6ms preprocess, 77.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 4 ovens, 74.4ms\n",
      "Speed: 4.3ms preprocess, 74.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 4 ovens, 63.9ms\n",
      "Speed: 2.9ms preprocess, 63.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 4 ovens, 68.6ms\n",
      "Speed: 2.5ms preprocess, 68.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "\n",
      "0: 640x544 3 ovens, 65.1ms\n",
      "Speed: 2.4ms preprocess, 65.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "WARNING  no tracks found!\n",
      "Processing complete! Output saved to 'parking_management.mp4'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from ultralytics import solutions\n",
    "\n",
    "# Path to dataset\n",
    "dataset_path = r\"../data/raw_img/parking\"\n",
    "video_path = os.path.join(dataset_path, \"parking_crop.mp4\")\n",
    "json_path = \"bounding_boxes.json\"  # path to parking annotations file\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Video writer\n",
    "video_writer = cv2.VideoWriter(\"parking_management.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Initialize parking management object - pass the json file directly\n",
    "management = solutions.ParkingManagement(model_path=\"yolov8n\", json_file=json_path)\n",
    "\n",
    "# Process the video\n",
    "while cap.isOpened():\n",
    "    ret, im0 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Process the frame with the ParkingManagement system\n",
    "    # This will handle detection, tracking, and spot analysis\n",
    "    im0 = management.process_data(im0)\n",
    "    \n",
    "    # Show the result\n",
    "    cv2.imshow(\"Parking Management\", im0)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to quit\n",
    "        break\n",
    "    \n",
    "    video_writer.write(im0)\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Processing complete! Output saved to 'parking_management.mp4'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 14 parking spots\n",
      "\n",
      "0: 640x544 2 microwaves, 70.6ms\n",
      "Speed: 3.1ms preprocess, 70.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 microwaves, 64.5ms\n",
      "Speed: 3.3ms preprocess, 64.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 (no detections), 63.3ms\n",
      "Speed: 2.6ms preprocess, 63.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 (no detections), 60.1ms\n",
      "Speed: 3.1ms preprocess, 60.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 (no detections), 58.7ms\n",
      "Speed: 2.8ms preprocess, 58.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 (no detections), 58.1ms\n",
      "Speed: 2.3ms preprocess, 58.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 (no detections), 59.8ms\n",
      "Speed: 2.8ms preprocess, 59.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 (no detections), 57.2ms\n",
      "Speed: 2.8ms preprocess, 57.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 55.6ms\n",
      "Speed: 2.9ms preprocess, 55.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 58.8ms\n",
      "Speed: 2.7ms preprocess, 58.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 57.2ms\n",
      "Speed: 2.4ms preprocess, 57.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.7ms\n",
      "Speed: 2.6ms preprocess, 55.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 56.1ms\n",
      "Speed: 2.5ms preprocess, 56.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.1ms\n",
      "Speed: 2.7ms preprocess, 54.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 53.8ms\n",
      "Speed: 2.7ms preprocess, 53.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.6ms\n",
      "Speed: 2.4ms preprocess, 53.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 (no detections), 55.1ms\n",
      "Speed: 3.1ms preprocess, 55.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 (no detections), 54.6ms\n",
      "Speed: 2.8ms preprocess, 54.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 (no detections), 52.5ms\n",
      "Speed: 2.9ms preprocess, 52.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.7ms\n",
      "Speed: 2.5ms preprocess, 55.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 (no detections), 53.4ms\n",
      "Speed: 2.6ms preprocess, 53.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.4ms\n",
      "Speed: 2.8ms preprocess, 53.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 62.1ms\n",
      "Speed: 2.5ms preprocess, 62.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.9ms\n",
      "Speed: 2.8ms preprocess, 55.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.7ms\n",
      "Speed: 2.6ms preprocess, 53.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 60.7ms\n",
      "Speed: 2.5ms preprocess, 60.7ms inference, 40.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 58.8ms\n",
      "Speed: 2.5ms preprocess, 58.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 58.6ms\n",
      "Speed: 3.1ms preprocess, 58.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 59.5ms\n",
      "Speed: 3.0ms preprocess, 59.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.4ms\n",
      "Speed: 2.8ms preprocess, 53.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.0ms\n",
      "Speed: 5.8ms preprocess, 55.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 55.8ms\n",
      "Speed: 2.3ms preprocess, 55.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 54.9ms\n",
      "Speed: 2.7ms preprocess, 54.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 53.8ms\n",
      "Speed: 2.5ms preprocess, 53.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 54.1ms\n",
      "Speed: 2.6ms preprocess, 54.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 54.9ms\n",
      "Speed: 2.8ms preprocess, 54.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 54.2ms\n",
      "Speed: 2.6ms preprocess, 54.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 53.8ms\n",
      "Speed: 2.3ms preprocess, 53.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 52.9ms\n",
      "Speed: 2.6ms preprocess, 52.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 52.4ms\n",
      "Speed: 3.1ms preprocess, 52.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 55.2ms\n",
      "Speed: 2.5ms preprocess, 55.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 54.0ms\n",
      "Speed: 2.8ms preprocess, 54.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 53.6ms\n",
      "Speed: 2.7ms preprocess, 53.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 3 ovens, 54.7ms\n",
      "Speed: 2.7ms preprocess, 54.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 3 ovens, 54.5ms\n",
      "Speed: 2.9ms preprocess, 54.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 3 ovens, 54.5ms\n",
      "Speed: 2.5ms preprocess, 54.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 3 ovens, 52.9ms\n",
      "Speed: 2.5ms preprocess, 52.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 3 ovens, 54.5ms\n",
      "Speed: 2.7ms preprocess, 54.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 3 ovens, 53.2ms\n",
      "Speed: 2.6ms preprocess, 53.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 3 ovens, 55.4ms\n",
      "Speed: 2.4ms preprocess, 55.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 3 ovens, 52.9ms\n",
      "Speed: 2.6ms preprocess, 52.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 3 ovens, 53.0ms\n",
      "Speed: 2.7ms preprocess, 53.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 4 ovens, 52.7ms\n",
      "Speed: 2.7ms preprocess, 52.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 4 ovens, 58.9ms\n",
      "Speed: 3.2ms preprocess, 58.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 4 ovens, 62.4ms\n",
      "Speed: 2.5ms preprocess, 62.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 4 ovens, 57.4ms\n",
      "Speed: 2.8ms preprocess, 57.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 3 ovens, 59.6ms\n",
      "Speed: 3.3ms preprocess, 59.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 3 ovens, 55.0ms\n",
      "Speed: 2.9ms preprocess, 55.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 54.3ms\n",
      "Speed: 2.7ms preprocess, 54.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.5ms\n",
      "Speed: 2.2ms preprocess, 55.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.1ms\n",
      "Speed: 2.6ms preprocess, 55.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 52.0ms\n",
      "Speed: 2.5ms preprocess, 52.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 (no detections), 52.1ms\n",
      "Speed: 2.5ms preprocess, 52.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 51.3ms\n",
      "Speed: 2.3ms preprocess, 51.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 52.5ms\n",
      "Speed: 2.9ms preprocess, 52.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.7ms\n",
      "Speed: 2.3ms preprocess, 53.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 56.4ms\n",
      "Speed: 2.3ms preprocess, 56.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 3 ovens, 54.0ms\n",
      "Speed: 2.3ms preprocess, 54.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 53.4ms\n",
      "Speed: 2.6ms preprocess, 53.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 53.7ms\n",
      "Speed: 3.1ms preprocess, 53.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 53.9ms\n",
      "Speed: 2.5ms preprocess, 53.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 51.8ms\n",
      "Speed: 2.7ms preprocess, 51.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.0ms\n",
      "Speed: 2.3ms preprocess, 54.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.1ms\n",
      "Speed: 3.0ms preprocess, 53.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 54.0ms\n",
      "Speed: 2.3ms preprocess, 54.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.2ms\n",
      "Speed: 2.6ms preprocess, 53.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 2 ovens, 59.2ms\n",
      "Speed: 3.0ms preprocess, 59.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 2 ovens, 54.3ms\n",
      "Speed: 2.6ms preprocess, 54.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 2 ovens, 54.9ms\n",
      "Speed: 2.4ms preprocess, 54.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 54.3ms\n",
      "Speed: 2.8ms preprocess, 54.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 52.3ms\n",
      "Speed: 2.8ms preprocess, 52.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 54.3ms\n",
      "Speed: 2.6ms preprocess, 54.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 2 ovens, 57.6ms\n",
      "Speed: 2.5ms preprocess, 57.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 2 ovens, 60.3ms\n",
      "Speed: 3.4ms preprocess, 60.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 55.9ms\n",
      "Speed: 2.7ms preprocess, 55.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 60.5ms\n",
      "Speed: 2.7ms preprocess, 60.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 2 ovens, 52.9ms\n",
      "Speed: 2.7ms preprocess, 52.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 53.4ms\n",
      "Speed: 3.0ms preprocess, 53.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 52.9ms\n",
      "Speed: 2.3ms preprocess, 52.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 52.7ms\n",
      "Speed: 2.4ms preprocess, 52.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 53.0ms\n",
      "Speed: 3.0ms preprocess, 53.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 50.5ms\n",
      "Speed: 3.0ms preprocess, 50.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 53.5ms\n",
      "Speed: 2.2ms preprocess, 53.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 54.9ms\n",
      "Speed: 2.7ms preprocess, 54.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 54.2ms\n",
      "Speed: 3.0ms preprocess, 54.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 54.9ms\n",
      "Speed: 2.7ms preprocess, 54.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 53.7ms\n",
      "Speed: 2.5ms preprocess, 53.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 54.0ms\n",
      "Speed: 2.6ms preprocess, 54.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 106.7ms\n",
      "Speed: 2.9ms preprocess, 106.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 57.4ms\n",
      "Speed: 2.6ms preprocess, 57.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 62.3ms\n",
      "Speed: 2.6ms preprocess, 62.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 55.7ms\n",
      "Speed: 2.7ms preprocess, 55.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 57.0ms\n",
      "Speed: 2.7ms preprocess, 57.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 65.0ms\n",
      "Speed: 2.8ms preprocess, 65.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 67.0ms\n",
      "Speed: 2.9ms preprocess, 67.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 62.5ms\n",
      "Speed: 3.0ms preprocess, 62.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 60.6ms\n",
      "Speed: 2.7ms preprocess, 60.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 55.9ms\n",
      "Speed: 2.8ms preprocess, 55.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 60.8ms\n",
      "Speed: 2.9ms preprocess, 60.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 61.6ms\n",
      "Speed: 2.7ms preprocess, 61.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 81.3ms\n",
      "Speed: 3.2ms preprocess, 81.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 77.7ms\n",
      "Speed: 2.8ms preprocess, 77.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 61.6ms\n",
      "Speed: 3.0ms preprocess, 61.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 53.9ms\n",
      "Speed: 2.9ms preprocess, 53.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 2 ovens, 52.9ms\n",
      "Speed: 2.7ms preprocess, 52.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 62.2ms\n",
      "Speed: 2.7ms preprocess, 62.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 67.1ms\n",
      "Speed: 3.0ms preprocess, 67.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 168.6ms\n",
      "Speed: 10.9ms preprocess, 168.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 2 ovens, 94.4ms\n",
      "Speed: 3.9ms preprocess, 94.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 2 ovens, 54.9ms\n",
      "Speed: 2.7ms preprocess, 54.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 2 ovens, 57.1ms\n",
      "Speed: 3.0ms preprocess, 57.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 2 ovens, 55.0ms\n",
      "Speed: 2.5ms preprocess, 55.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 2 ovens, 59.2ms\n",
      "Speed: 3.3ms preprocess, 59.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 2 ovens, 59.1ms\n",
      "Speed: 3.0ms preprocess, 59.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 55.4ms\n",
      "Speed: 2.7ms preprocess, 55.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 54.3ms\n",
      "Speed: 2.6ms preprocess, 54.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 57.8ms\n",
      "Speed: 5.3ms preprocess, 57.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 58.5ms\n",
      "Speed: 3.1ms preprocess, 58.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 53.5ms\n",
      "Speed: 3.2ms preprocess, 53.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 83.1ms\n",
      "Speed: 3.0ms preprocess, 83.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 80.7ms\n",
      "Speed: 3.3ms preprocess, 80.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 58.8ms\n",
      "Speed: 3.1ms preprocess, 58.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 60.3ms\n",
      "Speed: 3.7ms preprocess, 60.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.0ms\n",
      "Speed: 2.3ms preprocess, 54.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 53.6ms\n",
      "Speed: 2.4ms preprocess, 53.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 54.7ms\n",
      "Speed: 2.7ms preprocess, 54.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 3 ovens, 59.1ms\n",
      "Speed: 3.1ms preprocess, 59.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 3 ovens, 56.9ms\n",
      "Speed: 3.2ms preprocess, 56.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 60.6ms\n",
      "Speed: 3.1ms preprocess, 60.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 58.3ms\n",
      "Speed: 4.2ms preprocess, 58.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 55.4ms\n",
      "Speed: 3.0ms preprocess, 55.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 52.9ms\n",
      "Speed: 3.0ms preprocess, 52.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 57.8ms\n",
      "Speed: 2.8ms preprocess, 57.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.3ms\n",
      "Speed: 2.8ms preprocess, 54.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.3ms\n",
      "Speed: 2.8ms preprocess, 54.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 56.7ms\n",
      "Speed: 2.6ms preprocess, 56.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.9ms\n",
      "Speed: 2.6ms preprocess, 54.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.9ms\n",
      "Speed: 2.9ms preprocess, 54.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.2ms\n",
      "Speed: 4.2ms preprocess, 55.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 55.0ms\n",
      "Speed: 2.9ms preprocess, 55.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.9ms\n",
      "Speed: 2.5ms preprocess, 53.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.5ms\n",
      "Speed: 2.7ms preprocess, 53.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.6ms\n",
      "Speed: 2.7ms preprocess, 55.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.0ms\n",
      "Speed: 2.8ms preprocess, 54.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.5ms\n",
      "Speed: 2.7ms preprocess, 54.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.2ms\n",
      "Speed: 2.8ms preprocess, 53.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.4ms\n",
      "Speed: 2.9ms preprocess, 53.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 ovens, 53.6ms\n",
      "Speed: 3.0ms preprocess, 53.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.7ms\n",
      "Speed: 2.6ms preprocess, 53.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.2ms\n",
      "Speed: 2.8ms preprocess, 54.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.5ms\n",
      "Speed: 2.9ms preprocess, 53.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 61.8ms\n",
      "Speed: 41.7ms preprocess, 61.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.6ms\n",
      "Speed: 2.9ms preprocess, 53.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.6ms\n",
      "Speed: 2.7ms preprocess, 55.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 64.2ms\n",
      "Speed: 2.6ms preprocess, 64.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 57.4ms\n",
      "Speed: 2.9ms preprocess, 57.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 56.9ms\n",
      "Speed: 3.2ms preprocess, 56.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 70.3ms\n",
      "Speed: 3.0ms preprocess, 70.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 52.5ms\n",
      "Speed: 3.2ms preprocess, 52.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.0ms\n",
      "Speed: 2.8ms preprocess, 55.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.6ms\n",
      "Speed: 2.8ms preprocess, 53.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.1ms\n",
      "Speed: 2.6ms preprocess, 54.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 (no detections), 53.1ms\n",
      "Speed: 2.5ms preprocess, 53.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 (no detections), 55.7ms\n",
      "Speed: 2.8ms preprocess, 55.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 (no detections), 56.7ms\n",
      "Speed: 2.7ms preprocess, 56.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.6ms\n",
      "Speed: 2.7ms preprocess, 53.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.6ms\n",
      "Speed: 2.6ms preprocess, 54.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 59.3ms\n",
      "Speed: 2.7ms preprocess, 59.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.5ms\n",
      "Speed: 2.6ms preprocess, 53.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.9ms\n",
      "Speed: 2.9ms preprocess, 55.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.7ms\n",
      "Speed: 3.0ms preprocess, 53.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 54.5ms\n",
      "Speed: 2.9ms preprocess, 54.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.1ms\n",
      "Speed: 2.6ms preprocess, 53.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 54.0ms\n",
      "Speed: 2.6ms preprocess, 54.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.3ms\n",
      "Speed: 2.8ms preprocess, 53.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.7ms\n",
      "Speed: 2.8ms preprocess, 55.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 51.7ms\n",
      "Speed: 3.0ms preprocess, 51.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.4ms\n",
      "Speed: 2.4ms preprocess, 53.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.8ms\n",
      "Speed: 3.0ms preprocess, 53.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 52.6ms\n",
      "Speed: 2.6ms preprocess, 52.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 54.5ms\n",
      "Speed: 2.6ms preprocess, 54.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.2ms\n",
      "Speed: 2.8ms preprocess, 53.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 60.4ms\n",
      "Speed: 2.9ms preprocess, 60.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 58.6ms\n",
      "Speed: 3.1ms preprocess, 58.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 56.8ms\n",
      "Speed: 3.2ms preprocess, 56.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 55.6ms\n",
      "Speed: 2.9ms preprocess, 55.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.5ms\n",
      "Speed: 2.6ms preprocess, 53.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 54.4ms\n",
      "Speed: 2.4ms preprocess, 54.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.8ms\n",
      "Speed: 2.8ms preprocess, 54.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 56.0ms\n",
      "Speed: 2.7ms preprocess, 56.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.0ms\n",
      "Speed: 2.7ms preprocess, 54.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 microwaves, 1 oven, 53.9ms\n",
      "Speed: 2.8ms preprocess, 53.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 microwaves, 1 oven, 58.8ms\n",
      "Speed: 3.1ms preprocess, 58.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 microwaves, 1 oven, 59.7ms\n",
      "Speed: 3.2ms preprocess, 59.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.4ms\n",
      "Speed: 2.7ms preprocess, 53.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 microwaves, 1 oven, 55.6ms\n",
      "Speed: 2.9ms preprocess, 55.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.6ms\n",
      "Speed: 2.7ms preprocess, 53.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.7ms\n",
      "Speed: 2.7ms preprocess, 53.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.2ms\n",
      "Speed: 3.0ms preprocess, 53.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 54.1ms\n",
      "Speed: 2.4ms preprocess, 54.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.0ms\n",
      "Speed: 2.6ms preprocess, 53.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 microwaves, 1 oven, 101.4ms\n",
      "Speed: 2.6ms preprocess, 101.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.5ms\n",
      "Speed: 2.8ms preprocess, 53.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.5ms\n",
      "Speed: 2.8ms preprocess, 53.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.0ms\n",
      "Speed: 3.1ms preprocess, 53.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 54.4ms\n",
      "Speed: 2.3ms preprocess, 54.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.6ms\n",
      "Speed: 3.1ms preprocess, 53.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 56.4ms\n",
      "Speed: 2.8ms preprocess, 56.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 56.1ms\n",
      "Speed: 2.6ms preprocess, 56.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 54.0ms\n",
      "Speed: 2.8ms preprocess, 54.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 56.4ms\n",
      "Speed: 3.0ms preprocess, 56.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 60.0ms\n",
      "Speed: 2.8ms preprocess, 60.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 microwaves, 1 oven, 56.8ms\n",
      "Speed: 2.9ms preprocess, 56.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 microwaves, 1 oven, 54.2ms\n",
      "Speed: 2.8ms preprocess, 54.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 microwaves, 1 oven, 55.6ms\n",
      "Speed: 2.6ms preprocess, 55.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 56.1ms\n",
      "Speed: 2.8ms preprocess, 56.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 55.6ms\n",
      "Speed: 2.9ms preprocess, 55.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.0ms\n",
      "Speed: 2.7ms preprocess, 53.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 57.4ms\n",
      "Speed: 2.9ms preprocess, 57.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 57.1ms\n",
      "Speed: 2.6ms preprocess, 57.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 57.5ms\n",
      "Speed: 2.6ms preprocess, 57.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.8ms\n",
      "Speed: 2.6ms preprocess, 54.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 56.7ms\n",
      "Speed: 3.1ms preprocess, 56.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 59.8ms\n",
      "Speed: 5.4ms preprocess, 59.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.8ms\n",
      "Speed: 2.5ms preprocess, 53.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 52.7ms\n",
      "Speed: 2.6ms preprocess, 52.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 56.2ms\n",
      "Speed: 2.7ms preprocess, 56.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.9ms\n",
      "Speed: 3.0ms preprocess, 53.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 55.7ms\n",
      "Speed: 2.9ms preprocess, 55.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 53.3ms\n",
      "Speed: 2.6ms preprocess, 53.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 microwaves, 1 oven, 56.1ms\n",
      "Speed: 2.8ms preprocess, 56.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 microwaves, 1 oven, 56.4ms\n",
      "Speed: 2.9ms preprocess, 56.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 microwaves, 1 oven, 61.5ms\n",
      "Speed: 2.9ms preprocess, 61.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 microwaves, 1 oven, 56.1ms\n",
      "Speed: 2.8ms preprocess, 56.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 156.3ms\n",
      "Speed: 3.2ms preprocess, 156.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 64.4ms\n",
      "Speed: 3.2ms preprocess, 64.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 58.2ms\n",
      "Speed: 3.1ms preprocess, 58.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 75.8ms\n",
      "Speed: 3.0ms preprocess, 75.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 77.3ms\n",
      "Speed: 3.2ms preprocess, 77.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 2 microwaves, 1 oven, 66.5ms\n",
      "Speed: 3.2ms preprocess, 66.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 59.6ms\n",
      "Speed: 2.8ms preprocess, 59.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 56.1ms\n",
      "Speed: 2.8ms preprocess, 56.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 64.3ms\n",
      "Speed: 2.6ms preprocess, 64.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 70.4ms\n",
      "Speed: 2.8ms preprocess, 70.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 67.5ms\n",
      "Speed: 2.9ms preprocess, 67.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 63.5ms\n",
      "Speed: 3.0ms preprocess, 63.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 63.6ms\n",
      "Speed: 2.8ms preprocess, 63.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 121.1ms\n",
      "Speed: 3.1ms preprocess, 121.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 64.4ms\n",
      "Speed: 2.9ms preprocess, 64.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 57.9ms\n",
      "Speed: 2.8ms preprocess, 57.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 57.3ms\n",
      "Speed: 2.3ms preprocess, 57.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 55.8ms\n",
      "Speed: 2.9ms preprocess, 55.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 54.9ms\n",
      "Speed: 2.8ms preprocess, 54.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.6ms\n",
      "Speed: 2.3ms preprocess, 54.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 67.0ms\n",
      "Speed: 2.6ms preprocess, 67.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 58.1ms\n",
      "Speed: 2.5ms preprocess, 58.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 58.1ms\n",
      "Speed: 2.8ms preprocess, 58.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 72.7ms\n",
      "Speed: 3.4ms preprocess, 72.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 56.8ms\n",
      "Speed: 2.6ms preprocess, 56.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.9ms\n",
      "Speed: 2.7ms preprocess, 54.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.2ms\n",
      "Speed: 2.4ms preprocess, 55.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.5ms\n",
      "Speed: 3.0ms preprocess, 54.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 56.4ms\n",
      "Speed: 2.6ms preprocess, 56.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 microwave, 1 oven, 66.8ms\n",
      "Speed: 2.8ms preprocess, 66.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 62.5ms\n",
      "Speed: 2.8ms preprocess, 62.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 71.8ms\n",
      "Speed: 3.5ms preprocess, 71.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 63.4ms\n",
      "Speed: 3.2ms preprocess, 63.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.5ms\n",
      "Speed: 2.8ms preprocess, 54.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.3ms\n",
      "Speed: 2.6ms preprocess, 53.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 59.8ms\n",
      "Speed: 2.8ms preprocess, 59.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 56.9ms\n",
      "Speed: 2.6ms preprocess, 56.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.4ms\n",
      "Speed: 2.7ms preprocess, 55.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 54.5ms\n",
      "Speed: 2.5ms preprocess, 54.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.6ms\n",
      "Speed: 2.8ms preprocess, 55.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 56.1ms\n",
      "Speed: 2.4ms preprocess, 56.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.2ms\n",
      "Speed: 2.6ms preprocess, 55.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 53.2ms\n",
      "Speed: 2.7ms preprocess, 53.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 640x544 1 oven, 55.8ms\n",
      "Speed: 2.6ms preprocess, 55.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 544)\n",
      "Processing complete! Output saved to 'parking_management.mp4'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Path to dataset\n",
    "dataset_path = r\"../data/raw_img/parking\"\n",
    "video_path = os.path.join(dataset_path, \"parking_crop.mp4\")\n",
    "json_path = \"bounding_boxes.json\"  # path to parking annotations file\n",
    "\n",
    "# Load parking spots from JSON file\n",
    "with open(json_path, 'r') as f:\n",
    "    parking_data = json.load(f)\n",
    "    \n",
    "# Extract parking spots coordinates\n",
    "parking_spots = []\n",
    "for spot in parking_data:\n",
    "    points = spot['points']\n",
    "    # Convert the points to numpy array of integers\n",
    "    polygon_points = np.array(points, np.int32)\n",
    "    parking_spots.append(polygon_points)\n",
    "\n",
    "print(f\"Extracted {len(parking_spots)} parking spots\")\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Video writer\n",
    "video_writer = cv2.VideoWriter(\"parking_management.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "\n",
    "# Function to check if a spot is occupied\n",
    "def is_spot_occupied(spot_polygon, results, confidence_threshold=0.3, iou_threshold=0.2):\n",
    "    # Create a mask for the parking spot\n",
    "    mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, [spot_polygon], 255)\n",
    "    \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # Get confidence\n",
    "            conf = float(box.conf[0])\n",
    "            if conf < confidence_threshold:\n",
    "                continue\n",
    "                \n",
    "            # Get class ID\n",
    "            cls_id = int(box.cls[0])\n",
    "            \n",
    "            # Only consider cars (class 2), trucks (7) or buses (5)\n",
    "            if cls_id not in [2, 5, 7]:  # 2=car, 5=bus, 7=truck in COCO\n",
    "                continue\n",
    "                \n",
    "            # Get bounding box\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            \n",
    "            # Create a mask for the detection\n",
    "            detection_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "            cv2.rectangle(detection_mask, (x1, y1), (x2, y2), 255, -1)\n",
    "            \n",
    "            # Calculate intersection\n",
    "            intersection = cv2.bitwise_and(mask, detection_mask)\n",
    "            intersection_area = cv2.countNonZero(intersection)\n",
    "            \n",
    "            # Calculate IoU\n",
    "            spot_area = cv2.countNonZero(mask)\n",
    "            detection_area = cv2.countNonZero(detection_mask)\n",
    "            \n",
    "            # Avoid division by zero\n",
    "            if spot_area + detection_area - intersection_area == 0:\n",
    "                continue\n",
    "                \n",
    "            iou = intersection_area / float(spot_area + detection_area - intersection_area)\n",
    "            \n",
    "            if iou > iou_threshold:\n",
    "                return True\n",
    "                \n",
    "    return False\n",
    "\n",
    "# Process the video\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Run YOLOv8 inference on the frame\n",
    "    results = model(frame)\n",
    "    \n",
    "    # Draw parking spots and check if they're occupied\n",
    "    occupied_count = 0\n",
    "    for i, spot in enumerate(parking_spots):\n",
    "        # Check if spot is occupied\n",
    "        occupied = is_spot_occupied(spot, results)\n",
    "        if occupied:\n",
    "            occupied_count += 1\n",
    "        \n",
    "        # Draw the parking spot (green for empty, red for occupied)\n",
    "        color = (0, 0, 255) if occupied else (0, 255, 0)\n",
    "        cv2.polylines(frame, [spot], True, color, 2)\n",
    "        \n",
    "        # Add spot number\n",
    "        centroid = np.mean(spot, axis=0, dtype=np.int32)\n",
    "        cv2.putText(frame, str(i+1), tuple(centroid), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    # Draw YOLOv8 detections (only vehicles)\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # Only draw vehicle classes\n",
    "            cls_id = int(box.cls[0])\n",
    "            if cls_id in [2, 5, 7]:  # 2=car, 5=bus, 7=truck in COCO\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                conf = float(box.conf[0])\n",
    "                class_name = model.names[cls_id]\n",
    "                label = f\"{class_name}: {conf:.2f}\"\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    \n",
    "    # Add some statistics\n",
    "    empty_count = len(parking_spots) - occupied_count\n",
    "    total_spots = len(parking_spots)\n",
    "    cv2.putText(frame, f\"Available: {empty_count}/{total_spots}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    \n",
    "    # Show the result\n",
    "    cv2.imshow(\"Parking Management\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to quit\n",
    "        break\n",
    "    \n",
    "    video_writer.write(frame)\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Processing complete! Output saved to 'parking_management.mp4'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
